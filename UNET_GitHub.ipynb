{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from keras.optimizers import Adam, Nadam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm_notebook #, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow #, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img#,save_img\n",
    "\n",
    "import time\n",
    "t_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction = 0.7)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some parameters\n",
    "im_width = 256\n",
    "im_height = 256\n",
    "border = 5\n",
    "path_train = \"C:/Users/yousu/Downloads/BlastsOnline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and resize train images and masks\n",
    "def get_data(path, train=True):\n",
    "    ids = next(os.walk(path + \"/imagesResized_256_1368_updated\"))[2]\n",
    "    ids2= next(os.walk(path + \"/labelResized_256_1368_updated\"))[2]\n",
    "    X = np.zeros((len(ids), im_height, im_width, 1), dtype=np.float32)\n",
    "    if train:\n",
    "        y = np.zeros((len(ids2), im_height, im_width, 1), dtype=np.float32)\n",
    "    print('Getting and resizing images ... ')\n",
    "    for n, id_ in tqdm_notebook(enumerate(ids), total=len(ids)):\n",
    "        # Load images\n",
    "        img = load_img(path + '/imagesResized_256_1368_updated/' + id_, grayscale=True)\n",
    "        x_img = img_to_array(img)\n",
    "        x_img = resize(x_img, (im_width, im_height, 1), mode='constant', preserve_range=True)\n",
    "        X[n] = x_img / 255\n",
    "\n",
    "    for n, id_ in tqdm_notebook(enumerate(ids2), total=len(ids2)):\n",
    "        # Load masks\n",
    "        if train:\n",
    "            mask = img_to_array(load_img(path + '/labelResized_256_1368_updated/' + id_, grayscale=True))\n",
    "            mask = resize(mask, (im_width, im_height, 1), mode='constant', preserve_range=True)\n",
    "            y[n] = mask / 255\n",
    "\n",
    "        # Save images\n",
    "        #X[n] = x_img / 255\n",
    "        #if train:\n",
    "            #y[n] = mask / 255\n",
    "    print('Done!')\n",
    "    if train:\n",
    "        return X, y\n",
    "    else:\n",
    "        return X\n",
    "    \n",
    "X, y = get_data(path_train, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image = y[114]\n",
    "first_image = np.array(first_image)\n",
    "pixels = first_image.reshape((im_width, im_height))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and valid\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25, random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image = X_train[58]\n",
    "first_image = np.array(first_image)\n",
    "pixels = first_image.reshape((im_width, im_height))\n",
    "plt.imshow(pixels, cmap='gray')\n",
    "plt.show()\n",
    "print(len(y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if training data looks all right\n",
    "ix = random.randint(0, len(X_train))\n",
    "has_mask = y_train[ix].max() > 0\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "ax[0].imshow(X_train[ix,...,0], cmap='gray', interpolation='bilinear')\n",
    "if has_mask:\n",
    "    ax[0].contour(y_train[ix].squeeze(), colors='k', levels=[0.5])\n",
    "ax[0].set_title('Embryo')\n",
    "\n",
    "ax[1].imshow(y_train[ix].squeeze(), interpolation='bilinear', cmap='gray')\n",
    "ax[1].set_title('Label');\n",
    "#print(ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models import Unet\n",
    "#from segmentation_models.backbones import get_preprocessing\n",
    "from segmentation_models.losses import bce_jaccard_loss\n",
    "from segmentation_models.metrics import iou_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_block(input_tensor, n_filters, kernel_size=3, batchnorm=True):\n",
    "    # first layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
    "               padding=\"same\")(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    # second layer\n",
    "    x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
    "               padding=\"same\")(x)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    #Third Layer\n",
    "    #x = Conv2D(filters=n_filters, kernel_size=(kernel_size, kernel_size), kernel_initializer=\"he_normal\",\n",
    "               #padding=\"same\")(x)\n",
    "    #if batchnorm:\n",
    "        #x = BatchNormalization()(x)\n",
    "    #x = Activation(\"relu\")(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True):\n",
    "    # contracting path\n",
    "    c1 = conv2d_block(input_img, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "    p1 = Dropout(dropout*0.5)(p1)\n",
    "\n",
    "    c2 = conv2d_block(p1, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "\n",
    "    c3 = conv2d_block(p2, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "\n",
    "    c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "    \n",
    "    c5 = conv2d_block(p4, n_filters=n_filters*16, kernel_size=3, batchnorm=batchnorm)\n",
    "    #c4 = conv2d_block(p3, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "    \n",
    "    # expansive path\n",
    "    u6 = Conv2DTranspose(n_filters*8, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    #u6 = BatchNormalization()(u6) # added by me\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters=n_filters*8, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u7 = Conv2DTranspose(n_filters*4, (2, 2), strides=(2, 2), padding='same') (c4)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    #u7 = BatchNormalization()(u7) \n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters=n_filters*4, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u8 = Conv2DTranspose(n_filters*2, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    #u8 = BatchNormalization()(u8)\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters=n_filters*2, kernel_size=3, batchnorm=batchnorm)\n",
    "\n",
    "    u9 = Conv2DTranspose(n_filters*1, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    #u9 = BatchNormalization()(u9)\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters=n_filters*1, kernel_size=3, batchnorm=batchnorm)\n",
    "    \n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input((im_height, im_width, 1), name='img')\n",
    "model = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n",
    "lr=0.0001\n",
    "model.compile(optimizer=Nadam(lr), loss=bce_jaccard_loss, metrics=[iou_score])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_flipped_images(x):\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(20, 10))\n",
    "    ax[0].imshow(x[:,:,0], cmap='gray')\n",
    "    ax[0].set_title('original')\n",
    "    ax[1].imshow(np.fliplr(x[:,:,0]), cmap='gray')\n",
    "    ax[2].imshow(np.flipud(x[:,:,0]), cmap='gray')\n",
    "    ax[3].imshow(np.fliplr(np.flipud(x[:,:,0])), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_flipped_images(X_train[54])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_args = dict(horizontal_flip=True,\n",
    "                    vertical_flip=True,\n",
    "                    rotation_range=270,\n",
    "                    width_shift_range=0.1,\n",
    "                    height_shift_range=0.1,\n",
    "                    zoom_range=0.1)\n",
    "\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "seed = 2018\n",
    "bs = 16 #batchsize\n",
    "\n",
    "image_generator = image_datagen.flow(X_train, seed=seed, batch_size=bs, shuffle=True)\n",
    "mask_generator = mask_datagen.flow(y_train, seed=seed, batch_size=bs, shuffle=True)\n",
    "\n",
    "# Just zip the two generators to get a generator that provides augmented images and masks at the same time\n",
    "train_generator = zip(image_generator, mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"UNET_MOD01-{}\".format(int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(patience=15, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.05, patience=5, min_lr=0.000001, verbose=1),\n",
    "    ModelCheckpoint('model-Unetplus_01.h5', verbose=1, save_best_only=True, save_weights_only=True),\n",
    "    tensorboard\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit_generator(train_generator, steps_per_epoch=(len(X_train) // bs), epochs=100, callbacks=callbacks,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Learning curve\")\n",
    "plt.plot(results.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(results.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( np.argmin(results.history[\"val_loss\"]), np.min(results.history[\"val_loss\"]), marker=\"x\", color=\"r\", label=\"best model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"log_loss\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_weights('model-Unetplus_01.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set (this must be equals to the best log_loss)\n",
    "model.evaluate(X_valid, y_valid, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"UNETmodel.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on train, val and test\n",
    "preds_train = model.predict(X_train, verbose=1)\n",
    "preds_val = model.predict(X_valid, verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "preds_train_t = (preds_train > 0.5).astype(np.float32)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "img_path = 'C:/Users/yousu/Downloads/BlastsOnline/001_ChKrGPS1.png'\n",
    "img=mpimg.imread(img_path)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = img_to_array(img)\n",
    "x = resize(x, (256, 256, 1), mode='constant', preserve_range=True)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x = x / 255\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on train, val and test\n",
    "preds_val = model.predict(x, verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "preds_val_t = (preds_val > 0.5).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(X, y, preds, binary_preds, ix=None):\n",
    "    if ix is None:\n",
    "        ix = random.randint(0, len(X))\n",
    "\n",
    "    has_mask = y[ix].max() > 0\n",
    "\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(20, 10))\n",
    "    ax[0].imshow(X[ix, ..., 0], cmap='gray')\n",
    "    if has_mask:\n",
    "        ax[0].contour(y[ix].squeeze(), colors='r', levels=[0.7])\n",
    "    ax[0].set_title('Embryo')\n",
    "    ax[0].grid(False)\n",
    "\n",
    "    ax[1].imshow(y[ix].squeeze(), interpolation='bilinear', cmap='gray')\n",
    "    ax[1].set_title('Embryo_GT')\n",
    "    ax[1].grid(False)\n",
    "\n",
    "    ax[2].imshow(preds[ix].squeeze(), vmin=0, vmax=1)\n",
    "    if has_mask:\n",
    "        ax[2].contour(y[ix].squeeze(), colors='r', levels=[0.7])\n",
    "    ax[2].set_title('Embryo Predicted')\n",
    "    ax[2].grid(False)\n",
    "    \n",
    "    ax[3].imshow(binary_preds[ix].squeeze(), vmin=0, vmax=1)\n",
    "    if has_mask:\n",
    "        ax[3].contour(y[ix].squeeze(), colors='r', levels=[0.7])\n",
    "    ax[3].set_title('Embryo Predicted binary');\n",
    "    ax[3].grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if training data looks all right\n",
    "plot_sample(X_train, y_train, preds_train, preds_train_t, ix=66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if valid data looks all right\n",
    "plot_sample(X_valid, y_valid, preds_val, preds_val_t, ix=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import imageio\n",
    "\n",
    "for x in range (len(X_valid)):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    ax.imshow(X_valid[x, ...,0],cmap='gray')\n",
    "    ax.grid(False)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    fig.savefig('Original' + '_' + str(x+1) + '.png')\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "    ax.imshow(preds_val_t[x].squeeze(), vmin=0, vmax=1)\n",
    "    ax.contour(y_valid[x].squeeze(), colors='r', levels=[0.8])\n",
    "    ax.grid(False)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    fig.savefig('Predicted' + '_' + str(x+1) + '.png')\n",
    "    \n",
    "    image1 = Image.open('Original' + '_' + str(x+1) + '.png')\n",
    "    image2 = Image.open('Predicted' + '_' + str(x+1) + '.png')\n",
    "    image1 = image1.resize((500,500), Image.NEAREST)\n",
    "    image2 = image2.resize((500,500), Image.NEAREST)\n",
    "    alphaBlended1 = Image.blend(image1, image2, alpha=0.7)\n",
    "    imageio.imwrite('Overlay' + '_' + str(x+1) + '.png', alphaBlended1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "     #test accuracy\n",
    "     y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "     y_pred_neg = 1 - y_pred_pos\n",
    " \n",
    " \n",
    "     y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "     y_neg = 1 - y_pos\n",
    " \n",
    " \n",
    "     tp = K.sum(y_pos * y_pred_pos)\n",
    "     tn = K.sum(y_neg * y_pred_neg)\n",
    " \n",
    " \n",
    "     fp = K.sum(y_neg * y_pred_pos)\n",
    "     fn = K.sum(y_pos * y_pred_neg)\n",
    " \n",
    " \n",
    "     numerator = (tp + tn)\n",
    "     denominator = (tp+tn+fp+fn)\n",
    " \n",
    " \n",
    "     return numerator / (denominator + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "# compile the model\n",
    "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])\n",
    "\n",
    "# fit the model\n",
    "#history = model.fit(Xtrain, ytrain, validation_split=0.3, epochs=10, verbose=0)\n",
    "\n",
    "# evaluate the model\n",
    "y_valid = tf.convert_to_tensor(y_valid, np.float32)\n",
    "preds_val_t = tf.convert_to_tensor(preds_val_t, np.float32)\n",
    "#preds_val = tf.convert_to_tensor(preds_val, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(recall_m(y_valid,preds_val_t)))\n",
    "    print(sess.run(precision_m(y_valid,preds_val_t)))\n",
    "    print(sess.run(f1_m(y_valid,preds_val_t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1.\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = tf.layers.flatten(y_true)\n",
    "    y_pred_f = tf.layers.flatten(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1.0 - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(y_true, y_pred):\n",
    "    y_true = tf.convert_to_tensor(y_true, np.float32)\n",
    "    y_pred = tf.convert_to_tensor(y_pred, np.float32)\n",
    "    epsilon = 1e-15\n",
    "    #intersection = (y_pred * y_true).sum(dim=-2).sum(dim=-1)\n",
    "    #union = y_true.sum(dim=-2).sum(dim=-1) + y_pred.sum(dim=-2).sum(dim=-1)\n",
    "    y_true_f = tf.layers.flatten(y_true)\n",
    "    y_pred_f = tf.layers.flatten(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    union = tf.reduce_sum(y_true_f)+tf.reduce_sum(y_pred_f)\n",
    "\n",
    "    return (tf.reduce_mean(intersection + epsilon)/ (union - intersection + epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "     #test accuracy\n",
    "     y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "     y_pred_neg = 1 - y_pred_pos\n",
    " \n",
    " \n",
    "     y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "     y_neg = 1 - y_pos\n",
    " \n",
    " \n",
    "     tp = K.sum(y_pos * y_pred_pos)\n",
    "     tn = K.sum(y_neg * y_pred_neg)\n",
    " \n",
    " \n",
    "     fp = K.sum(y_neg * y_pred_pos)\n",
    "     fn = K.sum(y_pos * y_pred_neg)\n",
    " \n",
    " \n",
    "     numerator = tn\n",
    "     denominator = (tn+fp)\n",
    " \n",
    " \n",
    "     return numerator / (denominator + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(dice_coef(y_valid,preds_val_t)))\n",
    "    print(sess.run(jaccard(y_valid,preds_val_t)))\n",
    "    print(sess.run(accuracy(y_valid,preds_val_t)))\n",
    "    print(sess.run(specificity(y_valid, preds_val_t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
