{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "%matplotlib inline\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "from keras.optimizers import Adam, Nadam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm_notebook #, tnrange\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow #, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model, load_model, save_model\n",
    "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras import backend as K\n",
    "from keras import optimizers\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img#,save_img\n",
    "\n",
    "import time\n",
    "t_start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction = 0.7)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some parameters\n",
    "im_width = 256\n",
    "im_height = 256\n",
    "border = 5\n",
    "path_train = \"C:/Users/yousu/Downloads/BlastsOnline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and resize train images and masks\n",
    "def get_data(path, train=True):\n",
    "    ids = next(os.walk(path + \"/imagesResized_256_1368_updated\"))[2]\n",
    "    ids2= next(os.walk(path + \"/labelResized_256_1368_updated\"))[2]\n",
    "    X = np.zeros((len(ids), im_height, im_width, 1), dtype=np.float32)\n",
    "    if train:\n",
    "        y = np.zeros((len(ids2), im_height, im_width, 1), dtype=np.float32)\n",
    "    print('Getting and resizing images ... ')\n",
    "    for n, id_ in tqdm_notebook(enumerate(ids), total=len(ids)):\n",
    "        # Load images\n",
    "        img = load_img(path + '/imagesResized_256_1368_updated/' + id_, grayscale=True)\n",
    "        x_img = img_to_array(img)\n",
    "        x_img = resize(x_img, (im_width, im_height, 1), mode='constant', preserve_range=True)\n",
    "        X[n] = x_img / 255.0\n",
    "\n",
    "    for n, id_ in tqdm_notebook(enumerate(ids2), total=len(ids2)):\n",
    "        # Load masks\n",
    "        if train:\n",
    "            mask = img_to_array(load_img(path + '/labelResized_256_1368_updated/' + id_, grayscale=True))\n",
    "            mask = resize(mask, (im_width, im_height, 1), mode='constant', preserve_range=True)\n",
    "            y[n] = mask / 255.0\n",
    "\n",
    "        # Save images\n",
    "        #X[n] = x_img / 255\n",
    "        #if train:\n",
    "            #y[n] = mask / 255\n",
    "    print('Done!')\n",
    "    if train:\n",
    "        return X, y\n",
    "    else:\n",
    "        return X\n",
    "    \n",
    "X, y = get_data(path_train, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train and valid\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.25, random_state=2018)\n",
    "print(X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BatchActivate(x):\n",
    "    x = BatchNormalization()(x)\n",
    "    #x = Activation('relu')(x)\n",
    "    x = Activation('elu')(x)\n",
    "    return x\n",
    "\n",
    "def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n",
    "    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
    "    if activation == True:\n",
    "        x = BatchActivate(x)\n",
    "    return x\n",
    "\n",
    "def recurrent_block(x, filters, size, strides=(1,1), padding='same', activation=True, t=2):\n",
    "    for i in range(t):\n",
    "        if i==0:\n",
    "            x1 = Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
    "            if activation == True:\n",
    "                 x1 = BatchActivate(x1)\n",
    "        \n",
    "        x1 = Add()([x, x1])\n",
    "        x1 = Conv2D(filters, size, strides=strides, padding=padding)(x1)\n",
    "        if activation == True:\n",
    "             x1 = BatchActivate(x1)\n",
    "        #x1 = Add()([x, x1])        \n",
    "    return x1\n",
    "\n",
    "def residual_block(x, num_filters=16, batch_activate = False):\n",
    "    x = BatchActivate(x)\n",
    "    x1 = recurrent_block(x, num_filters, (3,3))\n",
    "    x1 = recurrent_block(x1, num_filters, (3,3))\n",
    "    \n",
    "    #x = Conv2D(num_filters, (1,1), strides=(1,1), padding='same')(x)\n",
    "    #x = Add()([x1, x])\n",
    "    if batch_activate:\n",
    "        x1 = BatchActivate(x1)\n",
    "    return x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "def build_model(input_layer, start_neurons, DropoutRatio = 0.5):\n",
    "    # 101 -> 50\n",
    "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(input_layer)\n",
    "    #conv1 = residual_block(conv1,start_neurons * 1)\n",
    "    conv1 = residual_block(conv1,start_neurons * 1, True)\n",
    "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
    "    pool1 = Dropout(DropoutRatio/2)(pool1)\n",
    "\n",
    "    # 50 -> 25\n",
    "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n",
    "    #conv2 = residual_block(conv2,start_neurons * 2)\n",
    "    conv2 = residual_block(conv2,start_neurons * 2, True)\n",
    "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
    "    pool2 = Dropout(DropoutRatio)(pool2)\n",
    "\n",
    "    # 25 -> 12\n",
    "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n",
    "    #conv3 = residual_block(conv3,start_neurons * 4)\n",
    "    conv3 = residual_block(conv3,start_neurons * 4, True)\n",
    "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
    "    pool3 = Dropout(DropoutRatio)(pool3)\n",
    "\n",
    "    # 12 -> 6\n",
    "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n",
    "    #conv4 = residual_block(conv4,start_neurons * 8)\n",
    "    conv4 = residual_block(conv4,start_neurons * 8, True)\n",
    "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
    "    pool4 = Dropout(DropoutRatio)(pool4)\n",
    "\n",
    "    # Middle\n",
    "    convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(pool4)\n",
    "    #convm = residual_block(convm,start_neurons * 16)\n",
    "    convm = residual_block(convm,start_neurons * 16, True)\n",
    "    \n",
    "    #Dilated Middle\n",
    "    #convm = bottleneck(pool4, filters_bottleneck=start_neurons * 16, mode='cascade', depth=4,\n",
    "    #           kernel_size=(3, 3), activation='elu')\n",
    "    #convm = residual_block(convm,start_neurons * 16)\n",
    "    #convm = residual_block(convm,start_neurons * 16, True)\n",
    "    \n",
    "    # 6 -> 12\n",
    "    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
    "    #conv4 = recurrent_block(conv4, start_neurons * 8, (3,3), activation=True, t=0)\n",
    "    #conv4 = res_path(conv4, start_neurons * 8, 1)\n",
    "    uconv4 = concatenate([deconv4, conv4])\n",
    "    uconv4 = BatchNormalization()(uconv4)\n",
    "    uconv4 = Dropout(DropoutRatio)(uconv4)\n",
    "    \n",
    "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n",
    "    #uconv4 = residual_block(uconv4,start_neurons * 8)\n",
    "    uconv4 = residual_block(uconv4,start_neurons * 8, True)\n",
    "    \n",
    "    # 12 -> 25\n",
    "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
    "    #deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"valid\")(uconv4)\n",
    "    #conv3 = recurrent_block(conv3, start_neurons * 4, (3,3), activation=True, t=1)\n",
    "    #conv3 = res_path(conv3, start_neurons * 4, 2)\n",
    "    uconv3 = concatenate([deconv3, conv3])\n",
    "    uconv3 = BatchNormalization()(uconv3)\n",
    "    uconv3 = Dropout(DropoutRatio)(uconv3)\n",
    "    \n",
    "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
    "    #uconv3 = residual_block(uconv3,start_neurons * 4)\n",
    "    uconv3 = residual_block(uconv3,start_neurons * 4, True)\n",
    "\n",
    "    # 25 -> 50\n",
    "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
    "    #conv2 = recurrent_block(conv2, start_neurons * 2, (3,3), activation=True, t=2)\n",
    "    #conv2 = res_path(conv2, start_neurons * 2, 3)\n",
    "    uconv2 = concatenate([deconv2, conv2])\n",
    "    uconv2 = BatchNormalization()(uconv2)\n",
    "        \n",
    "    uconv2 = Dropout(DropoutRatio)(uconv2)\n",
    "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
    "    #uconv2 = residual_block(uconv2,start_neurons * 2)\n",
    "    uconv2 = residual_block(uconv2,start_neurons * 2, True)\n",
    "    \n",
    "    # 50 -> 101\n",
    "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
    "    #deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"valid\")(uconv2)\n",
    "    #conv1 = recurrent_block(conv1, start_neurons * 1, (3,3), activation=True, t=3)\n",
    "    #conv1 = res_path(conv1, start_neurons * 1, 4)\n",
    "    uconv1 = concatenate([deconv1, conv1])\n",
    "    uconv1 = BatchNormalization()(uconv1)\n",
    "    \n",
    "    uconv1 = Dropout(DropoutRatio)(uconv1)\n",
    "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
    "    #uconv1 = residual_block(uconv1,start_neurons * 1)\n",
    "    uconv1 = residual_block(uconv1,start_neurons * 1, True)\n",
    "    \n",
    "    #uconv1 = Dropout(DropoutRatio/2)(uconv1)\n",
    "    #output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
    "    output_layer_noActi = Conv2D(1, (1,1), padding=\"same\", activation=None)(uconv1)\n",
    "    output_layer =  Activation('sigmoid')(output_layer_noActi)\n",
    "    \n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models import Unet\n",
    "#from segmentation_models.backbones import get_preprocessing\n",
    "from segmentation_models.losses import bce_jaccard_loss\n",
    "from segmentation_models.losses import bce_dice_loss\n",
    "from segmentation_models.metrics import iou_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "img_size_target = 256\n",
    "input_layer = Input((img_size_target, img_size_target, 1))\n",
    "output_layer = build_model(input_layer, 16,0.05)\n",
    "lr=.0001\n",
    "# del model\n",
    "model = Model(input_layer, output_layer)\n",
    "model.compile(optimizer=Nadam(lr), loss=bce_jaccard_loss, metrics=[iou_score])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_args = dict(horizontal_flip=True,\n",
    "                    vertical_flip=True,\n",
    "                    rotation_range=270,\n",
    "                    width_shift_range=0.1,\n",
    "                    height_shift_range=0.1,\n",
    "                    zoom_range=0.1)\n",
    "\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "seed = 2018\n",
    "bs = 8 #batchsize for gpu\n",
    "\n",
    "image_generator = image_datagen.flow(X_train, seed=seed, batch_size=bs, shuffle=True)\n",
    "mask_generator = mask_datagen.flow(y_train, seed=seed, batch_size=bs, shuffle=True)\n",
    "\n",
    "# Just zip the two generators to get a generator that provides augmented images and masks at the same time\n",
    "train_generator = zip(image_generator, mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"RCNN_04-{}\".format(int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir='logs/{}'.format(NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    #EarlyStopping(patience=15, verbose=1),\n",
    "    ReduceLROnPlateau(factor=0.05, patience=5, min_lr=0.000001, verbose=1),\n",
    "    ModelCheckpoint('model-RCNN_04.h5', verbose=1, save_best_only=True, save_weights_only=True),\n",
    "    tensorboard\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit_generator(train_generator, steps_per_epoch=(len(X_train) // bs), epochs=100, callbacks=callbacks,\n",
    "                              validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "model.load_weights('model-RESUNET_test_05.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set (this must be equals to the best log_loss)\n",
    "model.evaluate(X_valid, y_valid, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on train, val and test\n",
    "preds_train = model.predict(X_train, verbose=1)\n",
    "preds_val = model.predict(X_valid, verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "preds_train_t = (preds_train > 0.5).astype(np.float32)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "# compile the model\n",
    "#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc',f1_m,precision_m, recall_m])\n",
    "\n",
    "# fit the model\n",
    "#history = model.fit(Xtrain, ytrain, validation_split=0.3, epochs=10, verbose=0)\n",
    "\n",
    "# evaluate the model\n",
    "y_valid = tf.convert_to_tensor(y_valid, np.float32)\n",
    "preds_val_t = tf.convert_to_tensor(preds_val_t, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(recall_m(y_valid,preds_val_t)))\n",
    "    print(sess.run(precision_m(y_valid,preds_val_t)))\n",
    "    print(sess.run(f1_m(y_valid,preds_val_t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "     #test accuracy\n",
    "     y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "     y_pred_neg = 1 - y_pred_pos\n",
    " \n",
    " \n",
    "     y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "     y_neg = 1 - y_pos\n",
    " \n",
    " \n",
    "     tp = K.sum(y_pos * y_pred_pos)\n",
    "     tn = K.sum(y_neg * y_pred_neg)\n",
    " \n",
    " \n",
    "     fp = K.sum(y_neg * y_pred_pos)\n",
    "     fn = K.sum(y_pos * y_pred_neg)\n",
    " \n",
    " \n",
    "     numerator = (tp + tn)\n",
    "     denominator = (tp+tn+fp+fn)\n",
    " \n",
    " \n",
    "     return numerator / (denominator + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1.\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true = tf.convert_to_tensor(y_true, np.float32)\n",
    "    y_pred = tf.convert_to_tensor(y_pred, np.float32)\n",
    "    y_true_f = tf.layers.flatten(y_true)\n",
    "    y_pred_f = tf.layers.flatten(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return 1.0 - dice_coef(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(y_true, y_pred):\n",
    "    y_true = tf.convert_to_tensor(y_true, np.float32)\n",
    "    y_pred = tf.convert_to_tensor(y_pred, np.float32)\n",
    "    epsilon = 1e-15\n",
    "    #intersection = (y_pred * y_true).sum(dim=-2).sum(dim=-1)\n",
    "    #union = y_true.sum(dim=-2).sum(dim=-1) + y_pred.sum(dim=-2).sum(dim=-1)\n",
    "    y_true_f = tf.layers.flatten(y_true)\n",
    "    y_pred_f = tf.layers.flatten(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    union = tf.reduce_sum(y_true_f)+tf.reduce_sum(y_pred_f)\n",
    "\n",
    "    return (tf.reduce_mean(intersection + epsilon)/ (union - intersection + epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def specificity(y_true, y_pred):\n",
    "     #test accuracy\n",
    "     y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "     y_pred_neg = 1 - y_pred_pos\n",
    " \n",
    " \n",
    "     y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "     y_neg = 1 - y_pos\n",
    " \n",
    " \n",
    "     tp = K.sum(y_pos * y_pred_pos)\n",
    "     tn = K.sum(y_neg * y_pred_neg)\n",
    " \n",
    " \n",
    "     fp = K.sum(y_neg * y_pred_pos)\n",
    "     fn = K.sum(y_pos * y_pred_neg)\n",
    " \n",
    " \n",
    "     numerator = tn\n",
    "     denominator = (tn+fp)\n",
    " \n",
    " \n",
    "     return numerator / (denominator + K.epsilon())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    print(sess.run(dice_coef(y_valid,preds_val_t)))\n",
    "    print(sess.run(jaccard(y_valid,preds_val_t)))\n",
    "    print(sess.run(accuracy(y_valid,preds_val_t)))\n",
    "    print(sess.run(specificity(y_valid, preds_val_t)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
